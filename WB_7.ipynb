{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "–†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∫–ª–∞—Å—Å –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π –ø–æ –∞–Ω–∞–ª–æ–≥–∏–∏ —Å –∫–ª–∞—Å—Å–æ–º OurNeuralNetwork.\n",
    "–î–∞–Ω–Ω—ã–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏:\n",
    "‚àí —Ç—Ä–∏ –≤—Ö–æ–¥–∞ (ùë•1, ùë•2, ùë•3);\n",
    "‚àí —Ç—Ä–∏ –Ω–µ–π—Ä–æ–Ω–∞ –≤ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è—Ö (‚Ñé1, ‚Ñé2, ‚Ñé3);\n",
    "‚àí –≤—ã—Ö–æ–¥ (ùëú1).\n",
    "–ù–µ–π—Ä–æ–Ω—ã –∏–º–µ—é—Ç –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ –≤–µ—Å–∞ –∏ –ø–æ—Ä–æ–≥–∏:\n",
    "‚àí ùë§ = [0.5, 0.5, 0.5]\n",
    "‚àí ùëè = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8151036049051821\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class OurNeuralNetwork:\n",
    "\n",
    "    def __init__(self):\n",
    "        weights = np.array([0.5, 0.5, 0.5])\n",
    "        bias = 0\n",
    "\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.h3 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "\n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_h3 = self.h3.feedforward(x)\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2, out_h3]))\n",
    "        return out_o1\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return sigmoid(total)\n",
    "\n",
    "\n",
    "network = OurNeuralNetwork()\n",
    "x = np.array([2, 3, 4])\n",
    "print(network.feedforward(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "–†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∫–ª–∞—Å—Å –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π –ø–æ –∞–Ω–∞–ª–æ–≥–∏–∏ —Å –∫–ª–∞—Å—Å–æ–º OurNeuralNetwork.\n",
    "–î–∞–Ω–Ω—ã–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏:\n",
    "‚àí –¥–≤–∞ –≤—Ö–æ–¥–∞ (ùë•1, ùë•2);\n",
    "‚àí –¥–≤–∞ –Ω–µ–π—Ä–æ–Ω–∞ –≤ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è—Ö (‚Ñé1, ‚Ñé2);\n",
    "‚àí –¥–≤–∞ –≤—ã—Ö–æ–¥–∞ (ùëú1, ùëú2).\n",
    "–ù–µ–π—Ä–æ–Ω—ã –∏–º–µ—é—Ç –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ –≤–µ—Å–∞ –∏ –ø–æ—Ä–æ–≥–∏:\n",
    "‚àí ùë§ = [1, 0];\n",
    "‚àí ùëè = 1."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8757270529783324, 0.8757270529783324)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class OurNeuralNetwork:\n",
    "\n",
    "    def __init__(self):\n",
    "        weights = np.array([1, 0])\n",
    "        bias = 1\n",
    "\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "        self.o2 = Neuron(weights, bias)\n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self. h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
    "        out_o2 = self.o2.feedforward(np.array([out_h1, out_h2]))\n",
    "        return out_o1, out_o2\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return sigmoid(total)\n",
    "\n",
    "network = OurNeuralNetwork()\n",
    "x = np.array([2, 3])\n",
    "print(network.feedforward(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "–†–µ–∞–ª–∏–∑—É–π—Ç–µ –∫–ª–∞—Å—Å—ã –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –¥—Ä—É–≥–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π\n",
    "–∞–∫—Ç–∏–≤–∞—Ü–∏–∏"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.75\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    return tanh(x)\n",
    "\n",
    "def ReLU(x):\n",
    "    return max(0, x)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class TanhNeuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return tanh(total)\n",
    "\n",
    "class TanhOurNeuralNetwork:\n",
    "\n",
    "    def __init__(self):\n",
    "        weights = np.array([0.5, 0.5, 0.5])\n",
    "        bias = 0\n",
    "\n",
    "        self.h1 = TanhNeuron(weights, bias)\n",
    "        self.h2 = TanhNeuron(weights, bias)\n",
    "        self.h3 = TanhNeuron(weights, bias)\n",
    "        self.o1 = TanhNeuron(weights, bias)\n",
    "\n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_h3 = self.h3.feedforward(x)\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2, out_h3]))\n",
    "        return out_o1\n",
    "\n",
    "class ReLUNeutron:\n",
    "     def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "     def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return ReLU(total)\n",
    "\n",
    "class ReLuOurNeuralNetwork:\n",
    "\n",
    "    def __init__(self):\n",
    "        weights = np.array([0.5, 0.5, 0.5])\n",
    "        bias = 0\n",
    "\n",
    "        self.h1 = ReLUNeutron(weights, bias)\n",
    "        self.h2 = ReLUNeutron(weights, bias)\n",
    "        self.h3 = ReLUNeutron(weights, bias)\n",
    "        self.o1 = ReLUNeutron(weights, bias)\n",
    "\n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_h3 = self.h3.feedforward(x)\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2, out_h3]))\n",
    "        return out_o1\n",
    "\n",
    "network = ReLuOurNeuralNetwork()\n",
    "x = np.array([2, 3, 4])\n",
    "print(network.feedforward(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–ª–∞—Å—Å—ã MLPClassified –∏ MLPRegressor –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏\n",
    "—Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞. –ü—Ä–æ–≤–µ–¥–∏—Ç–µ –∞–Ω–∞–ª–∏–∑\n",
    "–∞—Ç—Ä–∏–±—É—Ç—ã, –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.\n",
    "–î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –º–æ–∂–µ—Ç–µ –≤–∑—è—Ç—å –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –ò—Ä–∏—Å–æ–≤:\n",
    "https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f\n",
    "7d537619d0e07d5ae3/iris.csv\n",
    "–∞ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∑–∞—Ä–∞–±–æ—Ç–Ω–æ–π –ø–ª–∞—Ç—ã –æ—Ç –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã:\n",
    "https://raw.githubusercontent.com/AnnaShestova/salary-years-simple-linear\u0002regression/master/Salary_Data.csv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Sizes :  (150, 4) (150,)\n",
      "[1 0 2 2 0 0 2 2 2 0 0 1 2 1 2]\n",
      "[1 0 2 2 0 0 2 1 2 0 0 1 2 1 2]\n",
      "Test Accuracy : 0.933\n",
      "Training Accuracy : 0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikas\\PycharmProjects\\artificial_intelligence.py\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\nikas\\PycharmProjects\\artificial_intelligence.py\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-7.06623286e-01  5.50073550e+04]\n",
      " [-1.42685160e+00  1.23132754e+05]\n",
      " [-7.62282224e-01  5.72266289e+04]\n",
      " [-1.40256041e+00  1.18178549e+05]\n",
      " [-8.78237279e-01  6.51099626e+04]\n",
      " [-1.32219779e+00  1.13800168e+05]]\n",
      "[[3.20000e+00 5.44450e+04]\n",
      " [1.05000e+01 1.21872e+05]\n",
      " [2.90000e+00 5.66420e+04]\n",
      " [9.50000e+00 1.16969e+05]\n",
      " [3.20000e+00 6.44450e+04]\n",
      " [9.60000e+00 1.12635e+05]]\n",
      "Test R*2 Score : -2.070\n",
      "Training R¬∞2 Score : -2.363\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits, load_boston, load_iris\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "digits = load_digits()\n",
    "iris = load_iris()\n",
    "\n",
    "X_digits, Y_digits = iris.data, iris.target\n",
    "print('Dataset Sizes : ', X_digits.shape, Y_digits.shape)\n",
    "boston = load_boston()\n",
    "X_boston, Y_boston = boston.data, boston.target\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_digits, Y_digits, train_size=0.80, test_size = 0.20, stratify=Y_digits, random_state = 123)\n",
    "mlp_classifier = MLPClassifier(random_state=123)\n",
    "mlp_classifier.fit(X_train, Y_train)\n",
    "Y_preds = mlp_classifier.predict(X_test)\n",
    "print(Y_preds[:15])\n",
    "print(Y_test[:15])\n",
    "print('Test Accuracy : %.3f'%mlp_classifier.score(X_test, Y_test))\n",
    "print('Training Accuracy : %.3f'%mlp_classifier.score(X_train, Y_train))\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/AnnaShestova/salary-years-simple-linear-regression/master/Salary_Data.csv'\n",
    "dataset = pd.read_csv(url)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(dataset.iloc[:, :].values, dataset.iloc[:, :].values,\n",
    "                                                    train_size=0.80, test_size=0.20, random_state=123)\n",
    "mlp_regressor = MLPRegressor(random_state=123)\n",
    "mlp_regressor.fit(X_train, Y_train)\n",
    "Y_preds = mlp_regressor.predict(X_test)\n",
    "print(Y_preds[:10])\n",
    "print(Y_test[:10])\n",
    "print('Test R*2 Score : %.3f' % mlp_regressor.score(X_test, Y_test))\n",
    "print('Training R¬∞2 Score : %.3f' % mlp_regressor.score(X_train, Y_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}